{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Introduction to data science: classification\n",
    "\n",
    "[**This notebook is available on Google Colab.**](https://colab.research.google.com/drive/1EcvFm-NiPqzysCrmYLaCm5Ez_TLzw9bt)\n",
    "\n",
    "You know about the _data_ side of **data science**, now we can find out about the _science_ :)\n",
    "\n",
    "Data science depends hugely on data, but the _science_ part requires us to select the best (i.e. optimal) model -- and this means having an objective measure of 'best' and a way to prove that you have found it.\n",
    "\n",
    "In this notebook, we will predict the **lithology** (a fancy name for rock type) from two physical measurements: P-wave velocity (Vp) and bulk density (rho). We will fit a **support vector machine**, a versatile learning algorithm.\n",
    "\n",
    "First we'll import some data. I'm using an extract from the Rock Property Catalog, https://github.com/scienxlab/datasets/tree/main/rpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/scienxlab/datasets/refs/heads/main/rpc/rpc-3-imbalanced.csv'\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "empty"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "empty"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "empty"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "empty"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A plot is usually the best way to meet the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "empty"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LITHS = ['limestone', 'dolomite', 'shale']\n",
    "\n",
    "def lith_index(y):\n",
    "    return [LITHS.index(lith) for lith in y]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "scatter = ax.scatter(*X.T, c=lith_index(df['Lithology']))\n",
    "ax.set_xlabel('Vp')\n",
    "ax.set_ylabel('Rho')\n",
    "handles, labels = scatter.legend_elements()\n",
    "legend = ax.legend(handles = handles, labels = LITHS, title=\"Lithology\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## A linear model: SVM\n",
    "\n",
    "\n",
    "The **support vector machine** is a reliable classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "empty"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "scatter = ax.scatter(*X.T, c=lith_index(df['Lithology']), s= 80)\n",
    "ax.scatter(*X.T, c=lith_index(y_pred), s=40, marker='x')\n",
    "ax.set_xlabel('Vp')\n",
    "ax.set_ylabel('Rho')\n",
    "handles, labels = scatter.legend_elements()\n",
    "legend = ax.legend(handles = handles, labels = LITHS, title=\"Lithology\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "empty"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**‚ùì What do we think? Are we satisfied?**\n",
    "\n",
    "<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Scoring\n",
    "\n",
    "Scores matter in all machine learning tasks. It is very common to see people reporting only **accuracy** for classification tasks, or only **R<sup>2</sup>** for regression tasks. It is almost never enough to only look at (or report) the 'obvious' score -- especially for multiclass problems like this one, and especially when there is class imbalance.\n",
    "\n",
    "**This is one of the most important review papers in all of machine learning: [Raschka 2018](https://arxiv.org/abs/1811.12808). Read it and share it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "empty"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "\n",
    "This matrix, and the associated display, are a common way to look at the performance of the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "empty"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's worth spending some time to understanding what the matrix is telling you. Think about true predictions, false positives, and false negatives.\n",
    "\n",
    "### Classification report\n",
    "\n",
    "This report summarizes some of the information contained in the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "empty"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "üí° It's worth taking a look at exactly what **precision**, **recall**, **f1**, **macro** and **weighted** (formerly **micro**) mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Visualization\n",
    "\n",
    "We can also inspect the so-called **decision surface** to see why the model classifies the data as it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "x_min, x_max, y_min, y_max = (X[:,0].min() - 200, X[:,0].max() + 200, \n",
    "                              X[:,1].min() - 0.05, X[:,1].max() + 0.05\n",
    "                             )\n",
    "xx, yy = np.meshgrid(\n",
    "    np.linspace(x_min, x_max, 1000),\n",
    "    np.linspace(y_min, y_max, 1000)\n",
    ")\n",
    "grid = np.vstack([xx.ravel(), yy.ravel()]).T\n",
    "\n",
    "zz = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "zz = np.array(lith_index(zz)).reshape(xx.shape)\n",
    "ax.contourf(xx, yy, zz)\n",
    "\n",
    "scatter = ax.scatter(*X.T, c=lith_index(df['Lithology']), edgecolor='k', s=30)\n",
    "ax.set_xlabel('Vp')\n",
    "ax.set_ylabel('Rho')\n",
    "handles, labels = scatter.legend_elements()\n",
    "legend = ax.legend(handles = handles, labels = LITHS, title=\"Lithology\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes there is also a domain-specific way to look at the results. For example, for wireline log data, we might like to look at a side-by-side comparison of the rock types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Validation\n",
    "\n",
    "Now that we have touched upon different evaluation criteria, we need to address another issue: fairness. Our test was not fair.\n",
    "\n",
    "We should not train the model then check its accuracy only on that same training dataset. It's cheating, because in the future we'd like to predict on data that the model has never seen. So we should test the model on data it has never seen.\n",
    "\n",
    "Let's hold out some validation data, or 'blind' data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "empty"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "<div style=\"background: #e0ffe0; border: solid 2px #d0f0d0; border-radius:3px; padding: 1em; color: darkgreen\">\n",
    "\n",
    "<h3>EXERCISE</h3>\n",
    "\n",
    "Now let's train a model _on only the training data_ and validate it properly _on only the test data_.\n",
    "\n",
    "**‚ùì Do we think the score will be better or worse than before?**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "svc = SVC(kernel='linear')\n",
    "\n",
    "svc.fit( ... )  # Replace the dots with the training data.\n",
    "\n",
    "y_pred = svc.predict( ... )  # What will we predict on?\n",
    "\n",
    "print(classification_report( ... ))  # What do we give the report function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**‚ùì What do we need to think about when splitting? In other words: what is the most important thing about the test data?**\n",
    "\n",
    "&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />\n",
    "\n",
    "First and foremost, the test data must look like data we expect in the future.\n",
    "\n",
    "We also need to think about:\n",
    "\n",
    "- **Independence** ‚Äî¬†can you shuffle the data without losing information?\n",
    "- **Identical distributions** ‚Äî¬†are both the train and test data from the same distribution?\n",
    "- **Reproducibility** ‚Äî¬†what can we do to make this reproducible?\n",
    "- **Stratification** ‚Äî¬†How can we deal with class imbalance?\n",
    "\n",
    "Can you demonstrate that the test sample is fair and reproducible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(*X_train.T, c=lith_index(y_train))\n",
    "plt.scatter(*X_test.T, c=lith_index(y_test), edgecolor='r')\n",
    "plt.xlabel('Vp')\n",
    "_ = plt.ylabel('Rho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, ((ax0, ax1), (ax2, ax3)) = plt.subplots(nrows=2, ncols=2, figsize=(12,8))\n",
    "\n",
    "sns.kdeplot(X_train[:, 0], bw_adjust=0.5, ax=ax0)\n",
    "sns.kdeplot(X_test[:, 0], bw_adjust=0.5, ax=ax0)\n",
    "ax0.set_xlabel('Vp')\n",
    "\n",
    "sns.histplot(X_train[:, 0], stat='density', kde=True, kde_kws={'bw_adjust':0.5}, legend=False, ax=ax1)\n",
    "sns.histplot(X_test[:, 0], stat='density', kde=True, kde_kws={'bw_adjust':0.5}, legend=False, ax=ax1)\n",
    "ax1.set_xlabel('Vp')\n",
    "\n",
    "sns.kdeplot(X_train[:, 1], bw_adjust=0.5, ax=ax2)\n",
    "sns.kdeplot(X_test[:, 1], bw_adjust=0.5, ax=ax2)\n",
    "ax2.set_xlabel('Rho')\n",
    "\n",
    "sns.histplot(X_train[:, 1], stat='density', kde=True, kde_kws={'bw_adjust':0.5}, legend=False, ax=ax3)\n",
    "sns.histplot(X_test[:, 1], stat='density', kde=True, kde_kws={'bw_adjust':0.5}, legend=False, ax=ax3)\n",
    "_ = ax3.set_xlabel('Rho')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Let's do it in the proper reproducible way this time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1337)\n",
    "\n",
    "svc = SVC(kernel='linear')\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## A non-linear SVM model\n",
    "\n",
    "If we employ the **kernel trick** we can fit a nonlinear model. Scikit-learn's `SVC` actually uses this by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "\n",
    "svc = SVC()  # Default is kernel='rbf'\n",
    "clf = svc.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "scatter = ax.scatter(*X_test.T, c=lith_index(y_test), s= 80)\n",
    "ax.scatter(*X_test.T, c=np.array(lith_index(y_pred)), s=40, marker='x', norm=mcolors.Normalize(vmin=0, vmax=2))\n",
    "ax.set_xlabel('Vp')\n",
    "ax.set_ylabel('Rho')\n",
    "handles, labels = scatter.legend_elements()\n",
    "legend = ax.legend(handles = handles, labels = LITHS, title=\"Lithology\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The score is muuuuuuuuuuuch worse, especially for the minority class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x_min, x_max, y_min, y_max = (X[:,0].min() - 200, X[:,0].max() + 200, \n",
    "                              X[:,1].min() - 0.05, X[:,1].max() + 0.05\n",
    "                             )\n",
    "xx, yy = np.meshgrid(\n",
    "    np.linspace(x_min, x_max, 1000),\n",
    "    np.linspace(y_min, y_max, 1000)\n",
    ")\n",
    "grid = np.vstack([xx.ravel(), yy.ravel()]).T\n",
    "\n",
    "zz = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "zz = np.array(lith_index(zz)).reshape(xx.shape)\n",
    "ax.contourf(xx, yy, zz)\n",
    "\n",
    "scatter = ax.scatter(*X.T, c=lith_index(df['Lithology']), edgecolor='k', s=30)\n",
    "ax.set_xlabel('Vp')\n",
    "ax.set_ylabel('Rho')\n",
    "handles, labels = scatter.legend_elements()\n",
    "legend = ax.legend(handles = handles, labels = LITHS, title=\"Lithology\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**‚ùì What could the problem be?**\n",
    "\n",
    "<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Scale matters\n",
    "\n",
    "Our two features operate on *very* different scales! (m/s and g/cm<sup>3</sup>). Some models do not mind this, others do. SVM is one of those! You can get a numerical feel for it by forcing equal axes while scatterplotting the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(*X_train.T)\n",
    "plt.axis('equal')\n",
    "plt.xlabel('Vp')\n",
    "_ = plt.ylabel('Rho')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Standardize the data\n",
    "\n",
    "It's essential to train SVMs on scaled data, usually the Z-scores of your data, i.e. zero mean, unit variance. This ensures that the different scales of the features is not causing a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "empty"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "This doesn't change how the data are relatively distributed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(12,4))\n",
    "ax0.scatter(*X_train.T)\n",
    "ax1.scatter(*X_train_sc.T)\n",
    "ax0.set_xlabel('Vp')\n",
    "ax0.set_ylabel('Rho')\n",
    "ax1.set_xlabel('Scaled Vp')\n",
    "_ = ax1.set_ylabel('Scaled Rho')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it dramatically changes how they are distributed in absolute terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "sns.kdeplot(X_train[:, [1,0]], ax=axs[0])\n",
    "sns.kdeplot(X_train_sc[:, [1,0]], ax=axs[1])\n",
    "axs[0].legend(['Vp', 'Rho'])\n",
    "_ = axs[1].legend(['Scaled Vp', 'Scaled Rho'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "<div style=\"background: #e0ffe0; border: solid 2px #d0f0d0; border-radius:3px; padding: 1em; color: darkgreen\">\n",
    "\n",
    "<h3>EXERCISE</h3>\n",
    "\n",
    "Re-fit the **linear** model and look at the scores.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "empty"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                 Previous report:\n",
    "\n",
    "|   | precision    | recall | f1-score | support |\n",
    "| ---- | ----- | ------- | ------ | -------|\n",
    "| dolomite | 0.85  | 0.96    | 0.90 | 48 |\n",
    "| limestone | 0.67 | 0.44    | 0.53 | 9 |\n",
    "| shale | 0.85   | 0.8    | 0.82 | 50 |\n",
    "| | | |  |  |\n",
    "| accuracy |  |  | 0.84 | 107 |\n",
    "| macro avg | 0.79 | 0.73 | 0.75 | 107  |\n",
    "| weighted avg | 0.84 | 0.84 | 0.83 | 107 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Solving one problem gives us a new one. Now we have a new pitfall: it is essential to scale the data now before inference -- although the model will happily make (terrible) predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "empty"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "empty"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "This is known as an \"out of distribution\" or OOD error, and it's a classic pitfall in machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Put everything in a pipeline\n",
    "\n",
    "This is the most flexible way to compose data pipelines in `sklearn`. It is usually better than implementing everything individually in a stepwise manner.\n",
    "\n",
    "For now, it won't change anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), SVC(kernel='linear'))\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "And now the nonlinear SVM is basically identical to the linear one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), SVC())\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Hyperparameter tuning\n",
    "\n",
    "Most algorithms have **hyperparameters** which control how the algorithm learns -- and which often implement some kind of **regularization**. This means different things for different algorithms, but in general it involves simplifying or smoothing the model in some way.\n",
    "\n",
    "For the [support vector machine](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html), there is a parameter `C` to control the model complexity (an SVM tries to satistfy two critera during optimization: wide margins (how far from the linear separation to the nearest point in each class) and few missclassified instances. Sometimes these constraints compete, and `C` allows us to \"select\" which criterion the model should prioritize. High `C` means high complexity and low regularization, see this [stackoverflow thread](https://stats.stackexchange.com/a/159051) for a nice visualization of what `C`does)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Looping!\n",
    "\n",
    "Let's write a loop to step over values of the regularization parameter `C`. Start with:\n",
    "\n",
    "    C = np.logspace(-3, 5, 17)\n",
    "    mean_val, mean_train = [], []\n",
    "    for Ci in C:\n",
    "        # Instantiate the pipeline, using `SVC(C=Ci)`.\n",
    "        # Get the f1_score for both train and test sets.\n",
    "        # Gather these scores in two lists.\n",
    "\n",
    "When you have 2 lists of mean scores, plot them and compare how they vary with C. Put the x-axis on a log scale with `plt.xscale('log')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "empty"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**‚ùì Do you see a potential issue here?**\n",
    "\n",
    "<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;<br />&nbsp;\n",
    "\n",
    "Sometimes you will get a lucky test split, sometimes not. This feels a bit aribtrary. And we might overfit this model selection process to the particular test set that we have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Cross validation\n",
    "\n",
    "Instead of choosing a single holdout set for evaluation, we can choose many. This is useful for tuning hyperparameters, for example.\n",
    "\n",
    "But then we have more ways to leak information into our evaluation, so it is smart to continue to hold out our `val` set.\n",
    "\n",
    "The other catch is that we now must use a pipeline, otherwise we leak information in the scaling of the data.\n",
    "\n",
    "Fair evaluation is hard!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "But now we can use folded cross-validation in a safe way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "#from sklearn.metrics import make_scorer\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), SVC(C=0.1))\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42) \n",
    "# StratifiedKFold is useful for handling potential class imbalanced splits!\n",
    "\n",
    "cross_validate(pipe,\n",
    "               X_train, y_train,\n",
    "               scoring='f1_weighted',\n",
    "               cv=skf,\n",
    "               return_train_score=True,\n",
    "               # Also useful: groups\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Notice that we no longer use `test` during the model fitting process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "<div style=\"background: #e0ffe0; border: solid 2px #d0f0d0; border-radius:3px; padding: 1em; color: darkgreen\">\n",
    "\n",
    "<h3>EXERCISE</h3>\n",
    "\n",
    "Use cross-validation in the loop over values of `C`. Start with:\n",
    "\n",
    "    C = np.logspace(-3, 5, 17)\n",
    "    mean_val, mean_train = [], []\n",
    "    for Ci in C:\n",
    "        # Instantiate the pipeline, using `SVC(C=Ci)`.\n",
    "        # Do the cross validation model fits with `cross_validate()`.\n",
    "        # Gather the means of the test and train scores.\n",
    "\n",
    "Then make the plot, as before.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "empty"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Explore the model zoo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "<div style=\"background: #e0ffe0; border: solid 2px #d0f0d0; border-radius:3px; padding: 1em; color: darkgreen\">\n",
    "\n",
    "<h3>EXERCISE</h3>\n",
    "\n",
    "- Add `Vs` (shear velocity) to the features and see if it improves the prediction quality.\n",
    "- Choose another algorithm to try a prediction with, and implement it in a pipeline.\n",
    "- Choose a hyperparameter of the new algorithm and tune it. (If you have done this kind of thing before, try tuning 2 or 3 hyperparameters with grid or random search.)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Test\n",
    "\n",
    "When you have tuned the predictor and are satisfied that it is as good as it can be, you can test your prediction power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "C_opt = C[np.argmax(mean_val)]\n",
    "C_opt\n",
    "C_opt = 5.0 # Alternatively, use C_opt = 5.0, which you get from a more refined search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), SVC(C=C_opt))\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "                    \n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with the model with default `C`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), SVC())\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "                    \n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "If you are satisfied (think hard about what this means... you really have to decide before you start the model fitting process) then you are ready to fit the final model. If not, you must start all over again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Using this model\n",
    "\n",
    "We do not want to use this model &mdash; if we like its performance then we should now retrain it on all the data. Presumably, this new model will be at least as good as the one trained on the training set, we just don't have a way to check it now üò¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X)\n",
    "X_ = scaler.transform(X)\n",
    "svc = SVC(C=C_opt).fit(X_, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "There is no way for us to test this model, but we should monitor it in production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<hr />\n",
    "\n",
    "<p style=\"color:gray\"> adapted from &copy; 2025 Matt Hall / Equinor CC BY.</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
